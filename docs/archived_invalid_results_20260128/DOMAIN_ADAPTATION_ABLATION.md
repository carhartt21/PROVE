# Domain Adaptation Ablation Study: Cross-Dataset Domain Generalization

**Last Updated:** 2026-01-22

## Overview

This experiment evaluates the **cross-dataset domain adaptation** capability of models trained on traffic-focused datasets (BDD10k, IDD-AW, MapillaryVistas) when tested on:
- **Cityscapes** (representing clear_day condition)
- **ACDC** (representing adverse weather conditions: foggy, night, rainy, snowy)

### Motivation

Understanding how models trained on one domain generalize to other weather/lighting conditions is critical for robust autonomous driving systems. This ablation study measures:
1. How well models maintain performance on clear conditions (Cityscapes)
2. How much performance degrades in adverse conditions (ACDC domains)
3. Which training datasets provide the best domain generalization

## Experimental Setup

### Training Datasets (Source Domains)

Models trained on these datasets will be evaluated:

| Dataset | Train Images | Test Images | Label Format | Notes |
|---------|-------------|-------------|--------------|-------|
| BDD10k | ~7,000 | ~1,000 | TrainID (0-18+255) | Berkeley Driving Dataset (segmentation subset) |
| IDD-AW | ~1,800 | ~450 | TrainID (0-19+255) | India Driving Dataset - Adverse Weather |
| MapillaryVistas | ~18,000 | ~2,000 | RGB Colorâ†’TrainID | Global street-level imagery, diverse conditions |

### Evaluation Datasets (Target Domains)

#### Clear Day Condition: Cityscapes

**Cityscapes** represents the clear_day baseline condition for comparison:

| City | Test Images | Structure |
|------|-------------|-----------|
| berlin | 544 | `test/images/Cityscapes/berlin/*_leftImg8bit.png` |
| bielefeld | 181 | `test/images/Cityscapes/bielefeld/*_leftImg8bit.png` |
| bonn | 46 | `test/images/Cityscapes/bonn/*_leftImg8bit.png` |
| leverkusen | 58 | `test/images/Cityscapes/leverkusen/*_leftImg8bit.png` |
| mainz | 298 | `test/images/Cityscapes/mainz/*_leftImg8bit.png` |
| munich | 398 | `test/images/Cityscapes/munich/*_leftImg8bit.png` |
| **Total** | **1,525** | |

Labels: `*_gtFine_labelIds.png` (Cityscapes labelID format, converted to trainID)

#### Adverse Conditions: ACDC

**ACDC (Adverse Conditions Dataset with Correspondences)** provides adverse weather domains:

| Domain | Test Images | Structure |
|--------|-------------|-----------|
| foggy | 500 | `test/images/ACDC/foggy/*_rgb_anon.png` |
| night | 506 | `test/images/ACDC/night/*_rgb_anon.png` |
| rainy | 500 | `test/images/ACDC/rainy/*_rgb_anon.png` |
| snowy | 500 | `test/images/ACDC/snowy/*_rgb_anon.png` |
| **Total** | **2,006** | |

Labels: `*_gt_labelIds.png` (Cityscapes labelID format, converted to trainID)

### Combined Domain Summary

| Domain | Source | Images | Condition |
|--------|--------|--------|-----------|
| clear_day | Cityscapes | 1,525 | â˜€ï¸ Sunny/overcast daytime |
| foggy | ACDC | 500 | ðŸŒ«ï¸ Dense fog |
| night | ACDC | 506 | ðŸŒ™ Nighttime |
| rainy | ACDC | 500 | ðŸŒ§ï¸ Rain |
| snowy | ACDC | 500 | â„ï¸ Snow |
| **Total** | | **3,531** | |

### Models

- **DeepLabV3+ ResNet-50** (deeplabv3plus_r50)
- **PSPNet ResNet-50** (pspnet_r50)
- **SegFormer MiT-B5** (segformer_mit-b5)

### All Available Strategies (27)

| Category | Strategies |
|----------|------------|
| **Baseline** | baseline |
| **Standard Augmentation** | std_autoaugment, std_cutmix, std_mixup, std_randaugment, std_std_photometric_distort |
| **GAN-based** | gen_cycleGAN, gen_CUT, gen_LANIT, gen_stargan_v2, gen_TSIT, gen_SUSTechGAN |
| **Diffusion-based** | gen_cyclediffusion, gen_flux_kontext, gen_Img2Img, gen_IP2P, gen_step1x_new, gen_step1x_v1p2 |
| **Other Generative** | gen_Attribute_Hallucination, gen_CNetSeg, gen_Qwen_Image_Edit, gen_UniControl, gen_VisualCloze, gen_Weather_Effect_Generator |
| **Classical Augmentation** | gen_albumentations_weather, gen_augmenters, gen_automold |

### Test Matrix

| Dimension | Options | Count |
|-----------|---------|-------|
| Source Datasets | BDD10k, IDD-AW | 2 |
| Models | pspnet_r50, segformer_mit-b5, deeplabv3plus_r50 | 3 |
| Strategies | All 27 strategies | 27 |
| Target Domains | clear_day, foggy, night, rainy, snowy | 5 |
| **Total Configurations** | 2 Ã— 3 Ã— 27 = **162** | |

### Training Configurations

Two training configurations are compared:

1. **Full Dataset Models** - Trained on all weather conditions from each source dataset
2. **Clear Day Baseline Models** - Trained only on clear_day subset of each source dataset

**Checkpoint Locations:**

```
# Full dataset models (trained on all weather conditions)
# Location: WEIGHTS_STAGE_2
${AWARE_DATA_ROOT}/WEIGHTS_STAGE_2/baseline/{dataset}/{model}/iter_80000.pth

# Clear day baseline models (trained on clear_day only)
# Location: WEIGHTS (original)
${AWARE_DATA_ROOT}/WEIGHTS/baseline/{dataset}/{model}/iter_80000.pth
```

> **Note:** The script automatically selects the correct weights directory based on the variant:
> - Full dataset (no `_clear_day` suffix) â†’ uses `WEIGHTS_STAGE_2/`
> - Clear day only (`_clear_day` suffix) â†’ uses `WEIGHTS/`

### Research Comparison

This setup enables comparing:
- **Full vs. Clear Day Training**: Does training on all weather conditions help adverse weather performance?
- **Domain Gap**: How much does each model degrade from clear_day to adverse conditions?

## Label Unification

### Critical Handling

Both Cityscapes and ACDC use Cityscapes labelID format (0-33), which must be converted to trainID (0-18) for evaluation:

```python
# Cityscapes labelID â†’ trainID mapping (from label_unification.py)
CITYSCAPES_ID_TO_TRAINID = {
    7: 0,   # road
    8: 1,   # sidewalk
    11: 2,  # building
    12: 3,  # wall
    13: 4,  # fence
    17: 5,  # pole
    19: 6,  # traffic light
    20: 7,  # traffic sign
    21: 8,  # vegetation
    22: 9,  # terrain
    23: 10, # sky
    24: 11, # person
    25: 12, # rider
    26: 13, # car
    27: 14, # truck
    28: 15, # bus
    31: 16, # train
    32: 17, # motorcycle
    33: 18, # bicycle
}
# All other IDs â†’ 255 (ignore)
```

### File Naming Conventions

| Dataset | Image Pattern | Label Pattern |
|---------|---------------|---------------|
| Cityscapes | `{city}_{seq}_{frame}_leftImg8bit.png` | `{city}_{seq}_{frame}_gtFine_labelIds.png` |
| ACDC | `{seq}_frame_{id}_rgb_anon.png` | `{seq}_frame_{id}_gt_labelIds.png` |

## Research Questions

### Primary Questions

1. **Q1: Cross-Dataset Generalization**
   - How well do models trained on BDD10k/IDD-AW/MapillaryVistas generalize to Cityscapes and ACDC?
   - Which source dataset produces the best domain adaptation across all conditions?

2. **Q2: Weather-Specific Performance**
   - How does performance vary across clear_day, foggy, night, rainy, snowy conditions?
   - Is the domain gap from clear_day (Cityscapes) to adverse (ACDC) larger than between source and clear_day?

3. **Q3: Architecture Sensitivity**
   - Do transformer-based models (SegFormer) generalize better than CNN-based (PSPNet)?
   - Is there an architecture-dataset interaction effect?

### Secondary Questions

4. **Q4: Geographic Domain Gap**
   - MapillaryVistas (global) vs BDD10k (US) vs IDD-AW (India) â†’ Cityscapes/ACDC (Europe)
   - Does geographic diversity in training help cross-dataset transfer?

5. **Q5: Dataset Scale Effect**
   - MapillaryVistas (~18k) vs BDD10k (~7k) vs IDD-AW (~1.8k)
   - Does larger training set size correlate with better adaptation?

## Expected Outcomes

### Hypothesis

1. **MapillaryVistas** should provide best cross-dataset generalization due to:
   - Largest training set
   - Most diverse weather conditions and geographic regions
   - Already includes some adverse weather samples

2. **IDD-AW** may perform surprisingly well on adverse conditions due to:
   - Native adverse weather training data
   - Despite smaller size, focused on weather variation

3. **Night domain** likely hardest for all source datasets:
   - Limited nighttime samples in training data
   - Significant appearance shift

4. **Clear_day (Cityscapes)** should show best performance:
   - Most similar to source training distributions
   - Well-lit, structured European urban scenes

## Metrics

- **mIoU** (mean Intersection over Union) - primary metric
- **Per-class IoU** - to identify which semantic classes suffer most in adaptation
- **Per-domain mIoU** - breakdown by weather condition (clear_day, foggy, night, rainy, snowy)

## Implementation

### Data Structure

```
${AWARE_DATA_ROOT}/FINAL_SPLITS/test/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ Cityscapes/          # clear_day condition
â”‚   â”‚   â”œâ”€â”€ berlin/*.png
â”‚   â”‚   â”œâ”€â”€ bielefeld/*.png
â”‚   â”‚   â”œâ”€â”€ bonn/*.png
â”‚   â”‚   â”œâ”€â”€ leverkusen/*.png
â”‚   â”‚   â”œâ”€â”€ mainz/*.png
â”‚   â”‚   â””â”€â”€ munich/*.png
â”‚   â””â”€â”€ ACDC/                # adverse conditions
â”‚       â”œâ”€â”€ foggy/*.png      # flat structure: *_rgb_anon.png
â”‚       â”œâ”€â”€ night/*.png
â”‚       â”œâ”€â”€ rainy/*.png
â”‚       â””â”€â”€ snowy/*.png
â””â”€â”€ labels/
    â”œâ”€â”€ Cityscapes/          # *_gtFine_labelIds.png
    â”‚   â””â”€â”€ {same city structure}
    â””â”€â”€ ACDC/                # *_gt_labelIds.png
        â””â”€â”€ {same domain structure}
```

### Label Transformation

```python
def transform_cityscapes_label(label: np.ndarray) -> np.ndarray:
    """Transform label from Cityscapes labelID to trainID format."""
    if label.ndim == 3:
        label = label[:, :, 0]
    return CITYSCAPES_LUT[label]  # Lookup table for fast conversion
```

## Job Submission Matrix

### Full Dataset Models (6 jobs)

| Source Dataset | Model | Checkpoint | Target Domains |
|---------------|-------|------------|----------------|
| BDD10k | pspnet_r50 | iter_80000.pth | clear_day + 4 ACDC domains |
| BDD10k | segformer_mit-b5 | iter_80000.pth | clear_day + 4 ACDC domains |
| IDD-AW | pspnet_r50 | iter_80000.pth | clear_day + 4 ACDC domains |
| IDD-AW | segformer_mit-b5 | iter_80000.pth | clear_day + 4 ACDC domains |
| MapillaryVistas | pspnet_r50 | iter_80000.pth | clear_day + 4 ACDC domains |
| MapillaryVistas | segformer_mit-b5 | iter_80000.pth | clear_day + 4 ACDC domains |

### Clear Day Baseline Models (6 jobs)

| Source Dataset | Model | Checkpoint | Target Domains |
|---------------|-------|------------|----------------|
| BDD10k | pspnet_r50_clear_day | iter_80000.pth | clear_day + 4 ACDC domains |
| BDD10k | segformer_mit-b5_clear_day | iter_80000.pth | clear_day + 4 ACDC domains |
| IDD-AW | pspnet_r50_clear_day | iter_80000.pth | clear_day + 4 ACDC domains |
| IDD-AW | segformer_mit-b5_clear_day | iter_80000.pth | clear_day + 4 ACDC domains |
| MapillaryVistas | pspnet_r50_clear_day | iter_80000.pth | clear_day + 4 ACDC domains |
| MapillaryVistas | segformer_mit-b5_clear_day | iter_80000.pth | clear_day + 4 ACDC domains |

**Total: 12 evaluation jobs** (each evaluates 5 domains: clear_day, foggy, night, rainy, snowy)

## Result Storage

Results will be saved to:
```
${AWARE_DATA_ROOT}/WEIGHTS/domain_adaptation_ablation/
â””â”€â”€ {source_dataset}/
    â”œâ”€â”€ {model}/                        # Full dataset models
    â”‚   â””â”€â”€ domain_adaptation_evaluation.json
    â””â”€â”€ {model}_clear_day/              # Clear day baseline models
        â””â”€â”€ domain_adaptation_evaluation.json
```

## Script Usage

### Python Script (Local/LSF)

```bash
# List all available checkpoints and their status
./scripts/submit_domain_adaptation_ablation.sh --list

# Submit ALL jobs (baseline + top 15 strategies)
./scripts/submit_domain_adaptation_ablation.sh --all

# Submit only baseline models
./scripts/submit_domain_adaptation_ablation.sh --all-full        # Full dataset models
./scripts/submit_domain_adaptation_ablation.sh --all-clear-day   # Clear_day only models

# Submit only augmentation strategies (no baseline)
./scripts/submit_domain_adaptation_ablation.sh --all-strategies

# Submit single strategy
./scripts/submit_domain_adaptation_ablation.sh --strategy gen_cyclediffusion

# Submit single baseline job (full dataset)
./scripts/submit_domain_adaptation_ablation.sh \
    --source-dataset BDD10k \
    --model pspnet_r50

# Submit single baseline job (clear_day)
# List all available strategies
python scripts/run_domain_adaptation_tests.py --list-strategies

# Single configuration test
python scripts/run_domain_adaptation_tests.py \
    --source-dataset bdd10k \
    --model pspnet_r50 \
    --strategy baseline

# All models for one strategy
python scripts/run_domain_adaptation_tests.py --all --strategy gen_cycleGAN

# Full matrix: all models Ã— all strategies (162 configs)
python scripts/run_domain_adaptation_tests.py --all --all-strategies

# Quick test mode (3 images per domain, for debugging)
python scripts/run_domain_adaptation_tests.py --all --strategy baseline --quick-test 3

# Dry run to preview jobs
python scripts/run_domain_adaptation_tests.py --all --all-strategies --dry-run
```

### LSF Job Submission

```bash
# Submit baseline jobs for all models
./scripts/submit_domain_adaptation_ablation.sh --all

# Submit single job
./scripts/submit_domain_adaptation_ablation.sh \
    --source-dataset BDD10k \
    --model pspnet_r50

# Dry run - show commands without executing
./scripts/submit_domain_adaptation_ablation.sh --all --dry-run

# Skip configurations that already have results
./scripts/submit_domain_adaptation_ablation.sh --all --skip-existing

```

### Baseline Checkpoint Availability

| Dataset | Model | Full (WEIGHTS_STAGE_2) | Clear_day (WEIGHTS) |
|---------|-------|:----------------------:|:-------------------:|
| BDD10k | pspnet_r50 | âœ… | âœ… |
| BDD10k | segformer_mit-b5 | âŒ | âœ… |
| IDD-AW | pspnet_r50 | âœ… | âŒ |
| IDD-AW | segformer_mit-b5 | âœ… | âŒ |
| MapillaryVistas | pspnet_r50 | âœ… | âœ… |
| MapillaryVistas | segformer_mit-b5 | âŒ | âœ… |

### Top 15 Augmentation Strategies

Models trained with these augmentation strategies will also be evaluated:

| Strategy | BDD10k | IDD-AW | MapillaryVistas |
|----------|:------:|:------:|:---------------:|
| gen_cyclediffusion | âœ… | âœ… | âŒ |
| gen_flux_kontext | âœ… | âœ… | âœ… |
| gen_step1x_new | âœ… | partial | âœ… |
| gen_step1x_v1p2 | âœ… | âœ… | âœ… |
| gen_stargan_v2 | âœ… | âœ… | âœ… |
| gen_cycleGAN | âœ… | âœ… | âœ… |
| gen_automold | âœ… | âœ… | âœ… |
| gen_albumentations_weather | âœ… | âœ… | âœ… |
| gen_TSIT | âœ… | âœ… | âŒ |
| gen_UniControl | âŒ | âœ… | âœ… |
| std_randaugment | âœ… | partial | âœ… |
| std_autoaugment | âœ… | âŒ | âœ… |
| std_cutmix | âœ… | âŒ | âœ… |
| std_mixup | âœ… | âŒ | âœ… |
| photometric_distort | âœ… | âœ… | âœ… |

> **Note:** Run `./scripts/submit_domain_adaptation_ablation.sh --list` to see the current status of all checkpoints.

## Analysis

After jobs complete, analyze with:
```bash
python analysis_scripts/analyze_domain_adaptation_ablation.py
```

This will generate:
- Cross-dataset performance heatmap (source vs domain)
- Per-domain breakdown bar charts
- Architecture comparison plots
- clear_day vs adverse conditions gap analysis
- Statistical significance tests

### Expected Output

```
Domain Adaptation Results - Full Dataset Models:
                         clear_day  foggy   night   rainy   snowy   Average
Source/Model
BDD10k/dlv3+              XX.X%    XX.X%   XX.X%   XX.X%   XX.X%    XX.X%
BDD10k/pspnet             XX.X%    XX.X%   XX.X%   XX.X%   XX.X%    XX.X%
BDD10k/segformer          XX.X%    XX.X%   XX.X%   XX.X%   XX.X%    XX.X%
IDD-AW/dlv3+              XX.X%    XX.X%   XX.X%   XX.X%   XX.X%    XX.X%
...

Domain Adaptation Results - Clear Day Baseline Models:
                              clear_day  foggy   night   rainy   snowy   Average
Source/Model
BDD10k/dlv3+_clear_day         XX.X%    XX.X%   XX.X%   XX.X%   XX.X%    XX.X%
BDD10k/pspnet_clear_day        XX.X%    XX.X%   XX.X%   XX.X%   XX.X%    XX.X%
BDD10k/segformer_clear_day     XX.X%    XX.X%   XX.X%   XX.X%   XX.X%    XX.X%
...

Full vs Clear Day Comparison (Î” mIoU):
Source/Model                   clear_day   foggy   night   rainy   snowy
BDD10k/dlv3+                    +X.X%     +X.X%   +X.X%   +X.X%   +X.X%
...
```
